#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ•°æ®åŠ è½½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import torch
from config import Config, get_default_config
from dataset import create_data_loaders

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½æ˜¯å¦æ­£å¸¸"""
    print("æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        # è·å–é»˜è®¤é…ç½®
        config = get_default_config()
        
        # å‡å°‘æ‰¹æ¬¡å¤§å°ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
        config.data.batch_size = 8
        config.data.num_workers = 2
        
        print(f"æ•°æ®é›†è·¯å¾„: {config.data.dataset_path}")
        print(f"æ‰¹æ¬¡å¤§å°: {config.data.batch_size}")
        print(f"è‰²ç›¸å‚æ•°: {config.data.color_jitter_params['hue']}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, class_ids, class_names = create_data_loaders(config)
        
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_loader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_loader.dataset)}")
        print(f"ç±»åˆ«æ•°: {len(class_ids)}")
        
        # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡
        print("\\næµ‹è¯•åŠ è½½è®­ç»ƒæ•°æ®æ‰¹æ¬¡...")
        train_iter = iter(train_loader)
        batch_data, batch_labels = next(train_iter)
        
        print(f"æ‰¹æ¬¡æ•°æ®å½¢çŠ¶: {batch_data.shape}")
        print(f"æ‰¹æ¬¡æ ‡ç­¾å½¢çŠ¶: {batch_labels.shape}")
        print(f"æ•°æ®ç±»å‹: {batch_data.dtype}")
        print(f"æ•°æ®èŒƒå›´: [{batch_data.min():.3f}, {batch_data.max():.3f}]")
        
        print("\\nâœ… æ•°æ®åŠ è½½æµ‹è¯•æˆåŠŸï¼")
        
    except Exception as e:
        print(f"\\nâŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == '__main__':
    success = test_data_loading()
    if success:
        print("\\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç°åœ¨å¯ä»¥å®‰å…¨åœ°å¼€å§‹è®­ç»ƒäº†ã€‚")
    else:
        print("\\nâš ï¸  è¯·å…ˆè§£å†³æ•°æ®åŠ è½½é—®é¢˜å†å¼€å§‹è®­ç»ƒã€‚")
